{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate placeholder data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2000\n",
    "n_test = 400\n",
    "\n",
    "def generate_data(n):\n",
    "    categories = ['category1', 'category2', 'category3', 'category4']\n",
    "    \n",
    "    column_int = np.random.randint(1, 100, n)\n",
    "    column_float = np.random.randn(n)\n",
    "    column_categorical = np.random.choice(categories, n)\n",
    "    column_boolean = np.random.randint(0, 2, n)\n",
    "    column_label = np.random.randint(0, 2, n)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict({'column_int': column_int,\\\n",
    "                                 'column_float': column_float,\\\n",
    "                                 'column_categorical': column_categorical,\\\n",
    "                                 'column_boolean': column_boolean,\\\n",
    "                                 'column_label': column_label})\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_train = generate_data(n)\n",
    "df_test = generate_data(n_test)\n",
    "df_train.to_csv('train.csv')\n",
    "df_test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category4    524\n",
      "category3    513\n",
      "category1    511\n",
      "category2    452\n",
      "Name: column_categorical, dtype: int64\n",
      "        id  column_int  column_float  column_categorical  column_boolean  \\\n",
      "0        0          49     -0.623765                   2               0   \n",
      "1        1          77     -2.543974                   1               1   \n",
      "2        2          45      1.058069                   2               0   \n",
      "3        3          67     -0.024730                   3               1   \n",
      "4        4          77      1.947579                   3               1   \n",
      "5        5          51      0.597288                   4               1   \n",
      "6        6          29     -0.710717                   2               1   \n",
      "7        7          52      1.366495                   4               0   \n",
      "8        8          92     -0.099043                   3               0   \n",
      "9        9           9      1.488385                   3               1   \n",
      "10      10          17     -0.515218                   2               0   \n",
      "11      11          58      0.386230                   4               0   \n",
      "12      12          69     -0.612513                   3               1   \n",
      "13      13          74     -1.064905                   2               0   \n",
      "14      14          51     -0.854213                   3               0   \n",
      "15      15          43      0.503234                   2               1   \n",
      "16      16          23     -0.119984                   2               0   \n",
      "17      17          20     -0.758220                   3               1   \n",
      "18      18          41      0.164847                   3               1   \n",
      "19      19          27     -0.803667                   2               1   \n",
      "20      20          37     -1.065625                   3               1   \n",
      "21      21          13     -0.416129                   1               0   \n",
      "22      22          27     -0.215224                   3               1   \n",
      "23      23          22     -0.425825                   4               1   \n",
      "24      24          44      0.333772                   1               1   \n",
      "25      25          33      1.235443                   2               1   \n",
      "26      26          25      1.320224                   1               1   \n",
      "27      27          62      0.094421                   3               1   \n",
      "28      28          32     -1.915324                   3               0   \n",
      "29      29          99      1.013674                   2               1   \n",
      "...    ...         ...           ...                 ...             ...   \n",
      "1970  1970          32      1.333840                   3               1   \n",
      "1971  1971          29     -0.210913                   4               0   \n",
      "1972  1972          62      1.291812                   4               0   \n",
      "1973  1973          57     -0.079549                   3               1   \n",
      "1974  1974          94     -0.175803                   3               1   \n",
      "1975  1975          36      1.154010                   3               0   \n",
      "1976  1976          80      1.705792                   1               0   \n",
      "1977  1977          82      1.540677                   2               0   \n",
      "1978  1978          53      1.296961                   1               1   \n",
      "1979  1979           9     -0.115907                   1               1   \n",
      "1980  1980          86     -0.004051                   1               0   \n",
      "1981  1981          52      0.269764                   2               0   \n",
      "1982  1982          53     -0.262654                   2               1   \n",
      "1983  1983          23      0.525778                   1               0   \n",
      "1984  1984          90     -0.252551                   1               0   \n",
      "1985  1985          80     -0.976859                   1               0   \n",
      "1986  1986           6     -1.534049                   1               0   \n",
      "1987  1987          30     -1.450143                   2               1   \n",
      "1988  1988          11     -1.135809                   2               1   \n",
      "1989  1989          14      0.246478                   3               1   \n",
      "1990  1990          75     -0.329854                   2               1   \n",
      "1991  1991          27      0.508678                   4               0   \n",
      "1992  1992          69     -0.422223                   3               1   \n",
      "1993  1993          72      0.267906                   2               0   \n",
      "1994  1994          99      0.272967                   3               0   \n",
      "1995  1995          92      0.989347                   4               0   \n",
      "1996  1996          20      0.656921                   1               1   \n",
      "1997  1997           5      0.372641                   1               0   \n",
      "1998  1998          25     -1.398989                   2               1   \n",
      "1999  1999          94      1.900059                   1               0   \n",
      "\n",
      "      column_label  \n",
      "0                1  \n",
      "1                1  \n",
      "2                0  \n",
      "3                1  \n",
      "4                1  \n",
      "5                1  \n",
      "6                0  \n",
      "7                1  \n",
      "8                0  \n",
      "9                0  \n",
      "10               1  \n",
      "11               0  \n",
      "12               0  \n",
      "13               0  \n",
      "14               0  \n",
      "15               1  \n",
      "16               1  \n",
      "17               1  \n",
      "18               0  \n",
      "19               0  \n",
      "20               1  \n",
      "21               0  \n",
      "22               1  \n",
      "23               0  \n",
      "24               1  \n",
      "25               1  \n",
      "26               0  \n",
      "27               1  \n",
      "28               0  \n",
      "29               1  \n",
      "...            ...  \n",
      "1970             1  \n",
      "1971             0  \n",
      "1972             1  \n",
      "1973             1  \n",
      "1974             0  \n",
      "1975             0  \n",
      "1976             1  \n",
      "1977             0  \n",
      "1978             1  \n",
      "1979             1  \n",
      "1980             1  \n",
      "1981             1  \n",
      "1982             1  \n",
      "1983             1  \n",
      "1984             0  \n",
      "1985             0  \n",
      "1986             1  \n",
      "1987             0  \n",
      "1988             0  \n",
      "1989             0  \n",
      "1990             1  \n",
      "1991             1  \n",
      "1992             0  \n",
      "1993             1  \n",
      "1994             0  \n",
      "1995             0  \n",
      "1996             0  \n",
      "1997             1  \n",
      "1998             1  \n",
      "1999             0  \n",
      "\n",
      "[2000 rows x 6 columns]\n",
      "[1]\tvalid_0's auc: 0.500525\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.502238\n",
      "[3]\tvalid_0's auc: 0.498675\n",
      "[4]\tvalid_0's auc: 0.500125\n",
      "[5]\tvalid_0's auc: 0.494662\n",
      "[6]\tvalid_0's auc: 0.496712\n",
      "[7]\tvalid_0's auc: 0.492274\n",
      "[8]\tvalid_0's auc: 0.493524\n",
      "[9]\tvalid_0's auc: 0.489749\n",
      "[10]\tvalid_0's auc: 0.491374\n",
      "[11]\tvalid_0's auc: 0.49685\n",
      "[12]\tvalid_0's auc: 0.49695\n",
      "[13]\tvalid_0's auc: 0.492224\n",
      "[14]\tvalid_0's auc: 0.493099\n",
      "[15]\tvalid_0's auc: 0.493624\n",
      "[16]\tvalid_0's auc: 0.494299\n",
      "[17]\tvalid_0's auc: 0.4982\n",
      "[18]\tvalid_0's auc: 0.4986\n",
      "[19]\tvalid_0's auc: 0.498175\n",
      "[20]\tvalid_0's auc: 0.4984\n",
      "[21]\tvalid_0's auc: 0.49885\n",
      "[22]\tvalid_0's auc: 0.498325\n",
      "[23]\tvalid_0's auc: 0.495762\n",
      "[24]\tvalid_0's auc: 0.495387\n",
      "[25]\tvalid_0's auc: 0.497587\n",
      "[26]\tvalid_0's auc: 0.497312\n",
      "[27]\tvalid_0's auc: 0.498212\n",
      "[28]\tvalid_0's auc: 0.496762\n",
      "[29]\tvalid_0's auc: 0.499762\n",
      "[30]\tvalid_0's auc: 0.498662\n",
      "[31]\tvalid_0's auc: 0.49995\n",
      "[32]\tvalid_0's auc: 0.498875\n",
      "[33]\tvalid_0's auc: 0.499887\n",
      "[34]\tvalid_0's auc: 0.498637\n",
      "[35]\tvalid_0's auc: 0.499837\n",
      "[36]\tvalid_0's auc: 0.499037\n",
      "[37]\tvalid_0's auc: 0.499337\n",
      "[38]\tvalid_0's auc: 0.498612\n",
      "[39]\tvalid_0's auc: 0.500313\n",
      "[40]\tvalid_0's auc: 0.500163\n",
      "[41]\tvalid_0's auc: 0.504325\n",
      "[42]\tvalid_0's auc: 0.505001\n",
      "[43]\tvalid_0's auc: 0.510251\n",
      "[44]\tvalid_0's auc: 0.510951\n",
      "[45]\tvalid_0's auc: 0.508801\n",
      "[46]\tvalid_0's auc: 0.510126\n",
      "[47]\tvalid_0's auc: 0.512676\n",
      "[48]\tvalid_0's auc: 0.512801\n",
      "[49]\tvalid_0's auc: 0.512126\n",
      "[50]\tvalid_0's auc: 0.513351\n",
      "[51]\tvalid_0's auc: 0.516352\n",
      "[52]\tvalid_0's auc: 0.516777\n",
      "[53]\tvalid_0's auc: 0.514226\n",
      "[54]\tvalid_0's auc: 0.515052\n",
      "[55]\tvalid_0's auc: 0.513476\n",
      "[56]\tvalid_0's auc: 0.514301\n",
      "[57]\tvalid_0's auc: 0.513851\n",
      "[58]\tvalid_0's auc: 0.514351\n",
      "[59]\tvalid_0's auc: 0.513001\n",
      "[60]\tvalid_0's auc: 0.513426\n",
      "[61]\tvalid_0's auc: 0.510851\n",
      "[62]\tvalid_0's auc: 0.509876\n",
      "[63]\tvalid_0's auc: 0.508201\n",
      "[64]\tvalid_0's auc: 0.507701\n",
      "[65]\tvalid_0's auc: 0.50295\n",
      "[66]\tvalid_0's auc: 0.5027\n",
      "[67]\tvalid_0's auc: 0.500075\n",
      "[68]\tvalid_0's auc: 0.4991\n",
      "[69]\tvalid_0's auc: 0.49705\n",
      "[70]\tvalid_0's auc: 0.49675\n",
      "[71]\tvalid_0's auc: 0.495075\n",
      "[72]\tvalid_0's auc: 0.494224\n",
      "[73]\tvalid_0's auc: 0.494299\n",
      "[74]\tvalid_0's auc: 0.494124\n",
      "[75]\tvalid_0's auc: 0.493649\n",
      "[76]\tvalid_0's auc: 0.493074\n",
      "[77]\tvalid_0's auc: 0.491924\n",
      "[78]\tvalid_0's auc: 0.491549\n",
      "[79]\tvalid_0's auc: 0.492024\n",
      "[80]\tvalid_0's auc: 0.492074\n",
      "[81]\tvalid_0's auc: 0.489124\n",
      "[82]\tvalid_0's auc: 0.489224\n",
      "[83]\tvalid_0's auc: 0.487099\n",
      "[84]\tvalid_0's auc: 0.487074\n",
      "[85]\tvalid_0's auc: 0.486024\n",
      "[86]\tvalid_0's auc: 0.486099\n",
      "[87]\tvalid_0's auc: 0.484073\n",
      "[88]\tvalid_0's auc: 0.483948\n",
      "[89]\tvalid_0's auc: 0.479923\n",
      "[90]\tvalid_0's auc: 0.479673\n",
      "[91]\tvalid_0's auc: 0.476398\n",
      "[92]\tvalid_0's auc: 0.476173\n",
      "[93]\tvalid_0's auc: 0.472947\n",
      "[94]\tvalid_0's auc: 0.473197\n",
      "[95]\tvalid_0's auc: 0.472622\n",
      "[96]\tvalid_0's auc: 0.472247\n",
      "[97]\tvalid_0's auc: 0.469122\n",
      "[98]\tvalid_0's auc: 0.468647\n",
      "[99]\tvalid_0's auc: 0.465422\n",
      "[100]\tvalid_0's auc: 0.465397\n",
      "[101]\tvalid_0's auc: 0.467147\n",
      "[102]\tvalid_0's auc: 0.467322\n",
      "[103]\tvalid_0's auc: 0.469897\n",
      "[104]\tvalid_0's auc: 0.469647\n",
      "[105]\tvalid_0's auc: 0.472247\n",
      "[106]\tvalid_0's auc: 0.472622\n",
      "[107]\tvalid_0's auc: 0.472947\n",
      "[108]\tvalid_0's auc: 0.472722\n",
      "[109]\tvalid_0's auc: 0.475648\n",
      "[110]\tvalid_0's auc: 0.475373\n",
      "[111]\tvalid_0's auc: 0.475748\n",
      "[112]\tvalid_0's auc: 0.476048\n",
      "[113]\tvalid_0's auc: 0.477773\n",
      "[114]\tvalid_0's auc: 0.477548\n",
      "[115]\tvalid_0's auc: 0.478223\n",
      "[116]\tvalid_0's auc: 0.478448\n",
      "[117]\tvalid_0's auc: 0.478948\n",
      "[118]\tvalid_0's auc: 0.478973\n",
      "[119]\tvalid_0's auc: 0.479698\n",
      "[120]\tvalid_0's auc: 0.479573\n",
      "[121]\tvalid_0's auc: 0.481073\n",
      "[122]\tvalid_0's auc: 0.481048\n",
      "[123]\tvalid_0's auc: 0.481948\n",
      "[124]\tvalid_0's auc: 0.482423\n",
      "[125]\tvalid_0's auc: 0.482973\n",
      "[126]\tvalid_0's auc: 0.482973\n",
      "[127]\tvalid_0's auc: 0.485899\n",
      "[128]\tvalid_0's auc: 0.486099\n",
      "[129]\tvalid_0's auc: 0.486474\n",
      "[130]\tvalid_0's auc: 0.486474\n",
      "[131]\tvalid_0's auc: 0.488199\n",
      "[132]\tvalid_0's auc: 0.488074\n",
      "[133]\tvalid_0's auc: 0.487449\n",
      "[134]\tvalid_0's auc: 0.487849\n",
      "[135]\tvalid_0's auc: 0.487649\n",
      "[136]\tvalid_0's auc: 0.487474\n",
      "[137]\tvalid_0's auc: 0.487174\n",
      "[138]\tvalid_0's auc: 0.486624\n",
      "[139]\tvalid_0's auc: 0.487724\n",
      "[140]\tvalid_0's auc: 0.487649\n",
      "[141]\tvalid_0's auc: 0.486124\n",
      "[142]\tvalid_0's auc: 0.486224\n",
      "[143]\tvalid_0's auc: 0.484948\n",
      "[144]\tvalid_0's auc: 0.484698\n",
      "[145]\tvalid_0's auc: 0.484498\n",
      "[146]\tvalid_0's auc: 0.484523\n",
      "[147]\tvalid_0's auc: 0.483823\n",
      "[148]\tvalid_0's auc: 0.483798\n",
      "[149]\tvalid_0's auc: 0.483273\n",
      "[150]\tvalid_0's auc: 0.482998\n",
      "[151]\tvalid_0's auc: 0.482848\n",
      "[152]\tvalid_0's auc: 0.482523\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.516777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['3']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "\n",
    "#\n",
    "# Prepare the data\n",
    "#\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "# get the labels\n",
    "y = train.column_label.values\n",
    "print(train[\"column_categorical\"].value_counts())\n",
    "\n",
    "train.replace({'column_categorical': {'category4': 4, 'category3': 3,'category1': 1, 'category2': 2}}, inplace=True)\n",
    "print(train)\n",
    "train.drop(['id', 'column_label'], inplace=True, axis=1)\n",
    "\n",
    "x = np.array(train)\n",
    "\n",
    "#\n",
    "# Create training and validation sets\n",
    "#\n",
    "x, x_test, y, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "#\n",
    "# Create the LightGBM data containers\n",
    "#\n",
    "\n",
    "categorical_features = [c for c, col in enumerate(train.columns) if 'cat' in col]\n",
    "categorical_features = [2]\n",
    "train_data = lightgbm.Dataset(x, label=y, feature_name=['1', '2', '3', '4'], categorical_feature=['3'])\n",
    "test_data = lightgbm.Dataset(x_test, label=y_test)\n",
    "\n",
    "#\n",
    "# Train the model\n",
    "#\n",
    "\n",
    "parameters = {\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "model = lightgbm.train(parameters,\n",
    "                       train_data,\n",
    "                       valid_sets=test_data,\n",
    "                       num_boost_round=5000,\n",
    "                       early_stopping_rounds=100)\n",
    "#\n",
    "# Create a submission\n",
    "#\n",
    "\n",
    "submission = pd.read_csv('test.csv')\n",
    "submission.replace({'column_categorical': {'category4': 4, 'category3': 3,'category1': 1, 'category2': 2}}, inplace=True)\n",
    "\n",
    "ids = submission['id'].values\n",
    "submission.drop(['id', 'column_label'], inplace=True, axis=1)\n",
    "\n",
    "\n",
    "x = submission.values\n",
    "y = model.predict(x)\n",
    "\n",
    "output = pd.DataFrame({'id': ids, 'target': y})\n",
    "output.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
